{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Keras to TensorflowLite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four types of post-training conversion for TensorflowLite models:\n",
    "\n",
    "1. __No quantization__: the model is converted with some optimization operation (e.g. pruning of training-related nodes), weights and activations are stored as float32 numbers.\n",
    "2. __Float16 quantization__: reduces model size by up to half (since all weights are now half the original size) with minimal loss in accuracy. Model still executes as float32 operations. Can speed up processing with GPUs.\n",
    "3. __Weight quantization__: quantizes *only the weights* from floating point to 8-bits integers, reducing the model size up to 4x and speeding up inference. During inference some operations will be executed with integer kernel, others with float kernel (*hybrid operators*).\n",
    "4. __Integer quantization__: all model values (weights and activations) are quantized to 8-bit integers. This results in a 4x reduction in model size and a 3 to 4x performance improvement on CPU performance. It needs a representative part of the dataset to quantize activations. If all the operations are supported it results in a __full integer quantization__, compatible with some hardware accelartors (e.g. Coral). Otherways the incompatible operations fall back in float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:20:51.951320Z",
     "start_time": "2020-04-09T13:20:51.102387Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:20:51.964993Z",
     "start_time": "2020-04-09T13:20:51.952411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "print(gpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:20:51.977085Z",
     "start_time": "2020-04-09T13:20:51.966065Z"
    }
   },
   "outputs": [],
   "source": [
    "# set the folder path where is located the model (saved in .h5)\n",
    "DIR = './models'\n",
    "model_name = 'model'\n",
    "\n",
    "model_fp = os.path.join(DIR, model_name + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion without quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:20:52.408902Z",
     "start_time": "2020-04-09T13:20:51.978098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 100, 100, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 50, 50, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 50, 50, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 25, 25, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 25, 25, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 64)                73792     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 78,370\n",
      "Trainable params: 78,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(model_fp)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the model and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:20:53.587079Z",
     "start_time": "2020-04-09T13:20:52.409855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ./models/model.tflite saved.\n"
     ]
    }
   ],
   "source": [
    "# import the converter loading the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "tflite_model_file = os.path.join(DIR,model_name) + \".tflite\"\n",
    "pathlib.Path(tflite_model_file).write_bytes(tflite_model)\n",
    "print(f\"Model {tflite_model_file} saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Float16 quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:20:53.648910Z",
     "start_time": "2020-04-09T13:20:53.588135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 100, 100, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 50, 50, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 50, 50, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 25, 25, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 25, 25, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 64)                73792     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 78,370\n",
      "Trainable params: 78,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(model_fp)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the converter object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:20:53.673930Z",
     "start_time": "2020-04-09T13:20:53.649831Z"
    }
   },
   "outputs": [],
   "source": [
    "# import the converter loading the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the model and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:20:54.711570Z",
     "start_time": "2020-04-09T13:20:53.675403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ./models/model_fp16.tflite saved.\n"
     ]
    }
   ],
   "source": [
    "tflite_fp16_model = converter.convert()\n",
    "\n",
    "tflite_model_fp16_file = os.path.join(DIR,model_name) + \"_fp16.tflite\"\n",
    "pathlib.Path(tflite_model_fp16_file).write_bytes(tflite_fp16_model)\n",
    "print(f\"Model {tflite_model_fp16_file} saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:20:54.771983Z",
     "start_time": "2020-04-09T13:20:54.712893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 100, 100, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 50, 50, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 50, 50, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 25, 25, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 25, 25, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 64)                73792     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 78,370\n",
      "Trainable params: 78,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(model_fp)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the converter object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:20:54.794660Z",
     "start_time": "2020-04-09T13:20:54.772948Z"
    }
   },
   "outputs": [],
   "source": [
    "# import the converter loading the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the model and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:20:55.827596Z",
     "start_time": "2020-04-09T13:20:54.795548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ./models/model_8bit.tflite saved.\n"
     ]
    }
   ],
   "source": [
    "tflite_8bit_model = converter.convert()\n",
    "\n",
    "tflite_model_8bit_file = os.path.join(DIR,model_name) + \"_8bit.tflite\"\n",
    "pathlib.Path(tflite_model_8bit_file).write_bytes(tflite_8bit_model)\n",
    "print(f\"Model {tflite_model_8bit_file} saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integer quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a **representative dataset** to perform activations quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:20:55.830877Z",
     "start_time": "2020-04-09T13:20:55.828701Z"
    }
   },
   "outputs": [],
   "source": [
    "input_size = (100,100)  # input size of the model\n",
    "data_range = 255  # range to normalize data\n",
    "n_data = 100      # number of representative inputs\n",
    "\n",
    "DATASET_DIR = './dataset' #the directory must contain at least n_data images\n",
    "\n",
    "dataset_fp = pathlib.Path(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:20:55.852720Z",
     "start_time": "2020-04-09T13:20:55.831728Z"
    }
   },
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files(str(dataset_fp/\"*\"))\n",
    "\n",
    "def representative_dataset_gen():\n",
    "    for _ in range(n_data):\n",
    "        for img_f in list_ds.take(1):\n",
    "            img = tf.io.decode_image(tf.io.read_file(img_f), channels=3, dtype=tf.dtypes.uint8)\n",
    "            img = tf.image.resize(img, input_size, method=tf.image.ResizeMethod.AREA)\n",
    "            yield ([img[None]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:20:55.911881Z",
     "start_time": "2020-04-09T13:20:55.853696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 100, 100, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 50, 50, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 50, 50, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 25, 25, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 25, 25, 8)         1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 64)                73792     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 78,370\n",
      "Trainable params: 78,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(model_fp)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the converter object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:20:55.934657Z",
     "start_time": "2020-04-09T13:20:55.912822Z"
    }
   },
   "outputs": [],
   "source": [
    "# import the converter loading the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the model and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:20:57.565330Z",
     "start_time": "2020-04-09T13:20:55.935550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ./models/model_integer.tflite saved.\n"
     ]
    }
   ],
   "source": [
    "tflite_integer_model = converter.convert()\n",
    "\n",
    "tflite_model_integer_file = os.path.join(DIR,model_name) + \"_integer.tflite\"\n",
    "pathlib.Path(tflite_model_integer_file).write_bytes(tflite_integer_model)\n",
    "print(f\"Model {tflite_model_integer_file} saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full integer quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a **representative dataset** to perform activations quantization. All the operations must be supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:20:57.568453Z",
     "start_time": "2020-04-09T13:20:57.566400Z"
    }
   },
   "outputs": [],
   "source": [
    "input_size = (100,100)  # input size of the model\n",
    "data_range = 255  # range to normalize data\n",
    "n_data = 100      # number of representative inputs\n",
    "\n",
    "DATASET_DIR = './dataset' #the directory must contain at least n_data images\n",
    "\n",
    "dataset_fp = pathlib.Path(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:20:57.584262Z",
     "start_time": "2020-04-09T13:20:57.569241Z"
    }
   },
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files(str(dataset_fp/\"*\"))\n",
    "\n",
    "def representative_dataset_gen():\n",
    "    for _ in range(n_data):\n",
    "        for img_f in list_ds.take(1):\n",
    "            img = tf.io.decode_image(tf.io.read_file(img_f), channels=3, dtype=tf.dtypes.uint8)\n",
    "            img = tf.image.resize(img, input_size, method=tf.image.ResizeMethod.AREA)\n",
    "            yield ([img[None]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the converter object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:20:57.734953Z",
     "start_time": "2020-04-09T13:20:57.585170Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# import the converter loading the model\n",
    "converter = tf.compat.v1.lite.TFLiteConverter.from_keras_model_file(model_fp) #TF2.0 currently not compatible\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the model and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-09T13:20:59.331969Z",
     "start_time": "2020-04-09T13:20:57.735890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ./models/model_full_integer.tflite saved.\n"
     ]
    }
   ],
   "source": [
    "tflite_full_integer_model = converter.convert()\n",
    "\n",
    "tflite_model_full_integer_file = os.path.join(DIR,model_name) + \"_full_integer.tflite\"\n",
    "pathlib.Path(tflite_model_full_integer_file).write_bytes(tflite_full_integer_model)\n",
    "print(f\"Model {tflite_model_full_integer_file} saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
