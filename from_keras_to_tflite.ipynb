{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Keras to TensorflowLite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three types of post-training quantiziation for TensorflowLite models.\n",
    "\n",
    "1. __Float16 quantization__: reduce model size by up to half (since all weights are now half the original size) with minimal loss in accuracy. Can speed up processing with GPUs.\n",
    "2. __Weight quantization__: quantizes *only the weights* from floating point to 8-bits integers, reducing the model size up to 4x and speeding up inference. During inference some operations will be executed with integer kernel, others with float kernel (*hybrid operators*).\n",
    "3. __Integer quantization__: all model values (weights and activations) are quantized to 8-bit integers. This results in a 4x reduction in model size and a 3 to 4x performance improvement on CPU performance. It needs a rapresentative part of the dataset to qunatize activations. If all the operations are supported it results in a __full integer quantization__, compatible with some hardware accelartors (e.g. Coral). Otherways the incompatible operations fall back in float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T12:16:34.157609Z",
     "start_time": "2020-01-30T12:16:28.241327Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-30T12:16:34.178027Z",
     "start_time": "2020-01-30T12:16:34.175315Z"
    }
   },
   "outputs": [],
   "source": [
    "# set the folder path where is located the model \n",
    "DIR = './bin'\n",
    "name_model = 'model.h5'\n",
    "\n",
    "model_fp = os.path.join(DIR, name_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Conversion without quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tf.keras.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Convert the model and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import the converter loading the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_fp)\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "tflite_model_file = os.path.join(DIR,\"model.tflite\")\n",
    "pathlib.Path(tflite_model_file).write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Float16 quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tf.keras.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Create the converter object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import the converter loading the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_fp)\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Convert the model and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tflite_fp16_model = converter.convert()\n",
    "\n",
    "tflite_model_fp16_file = os.path.join(DIR,\"model_fp16.tflite\")\n",
    "pathlib.Path(tflite_model_fp16_file).write_bytes(tflite_fp16_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Weight quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tf.keras.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Create the converter object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import the converter loading the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_fp)\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Convert the model and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tflite_8bit_model = converter.convert()\n",
    "\n",
    "tflite_model_8bit_file = os.path.join(DIR,\"model_8bit.tflite\")\n",
    "pathlib.Path(tflite_model_8bit_file).write_bytes(tflite_8bit_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integer quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:15:26.124545Z",
     "start_time": "2020-01-31T09:15:26.121274Z"
    }
   },
   "outputs": [],
   "source": [
    "input_size = (150,150)  # input size of the model\n",
    "data_range = 255  # range to normalize data\n",
    "n_data = 100      # number of representative inputs\n",
    "\n",
    "DATASET_DIR = './dataset' #the directory must contain at least n_data images\n",
    "\n",
    "dataset_fp = pathlib.Path(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:19:40.639630Z",
     "start_time": "2020-01-31T09:19:40.629344Z"
    }
   },
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files(str(dataset_fp/\"*\"))\n",
    "\n",
    "def representative_dataset_gen():\n",
    "    for _ in range(n_data):\n",
    "        for img_f in list_ds.take(1):\n",
    "            img = tf.io.decode_image(tf.io.read_file(img_f), channels=3, dtype=tf.dtypes.uint8)\n",
    "            img = tf.image.resize(img, input_size, method=tf.image.ResizeMethod.AREA)\n",
    "            yield ([img[None]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the converter object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the converter loading the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model_file(os.path.join(DIR, name_model))\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the model and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_integer_model = converter.convert()\n",
    "\n",
    "tflite_model_integer_file = os.path.join(DIR,\"model_integer.tflite\")\n",
    "pathlib.Path(tflite_model_integer_file).write_bytes(tflite_integer_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Full integer quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:15:26.124545Z",
     "start_time": "2020-01-31T09:15:26.121274Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_size = (150,150)  # input size of the model\n",
    "data_range = 255  # range to normalize data\n",
    "n_data = 100      # number of representative inputs\n",
    "\n",
    "DATASET_DIR = './dataset' #the directory must contain at least n_data images\n",
    "\n",
    "dataset_fp = pathlib.Path(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:19:40.639630Z",
     "start_time": "2020-01-31T09:19:40.629344Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files(str(dataset_fp/\"*\"))\n",
    "\n",
    "def representative_dataset_gen():\n",
    "    for _ in range(n_data):\n",
    "        for img_f in list_ds.take(1):\n",
    "            img = tf.io.decode_image(tf.io.read_file(img_f), channels=3, dtype=tf.dtypes.uint8)\n",
    "            img = tf.image.resize(img, input_size, method=tf.image.ResizeMethod.AREA)\n",
    "            yield ([img[None]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tf.keras.load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Create the converter object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import the converter loading the model\n",
    "converter = tf.compat.v1.lite.TFLiteConverter.from_keras_model_file(os.path.join(DIR, name_model)) #TF2.0 currently not compatible\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Convert the model and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tflite_integer_model = converter.convert()\n",
    "\n",
    "tflite_model_integer_file = os.path.join(DIR,\"model_integer.tflite\")\n",
    "pathlib.Path(tflite_model_integer_file).write_bytes(tflite_integer_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
