{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Keras to TensorflowLite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four types of conversion for TensorflowLite models. Optionally there are three types of post-training quantization.\n",
    "\n",
    "1. __No quantization__: the model is converted with some optimization operation (e.g. pruning of training-related nodes), weights and activations are stored as float32 numbers.\n",
    "2. __Float16 quantization__: reduces model size by up to half (since all weights are now half the original size) with minimal loss in accuracy. Can speed up processing with GPUs.\n",
    "3. __Weight quantization__: quantizes *only the weights* from floating point to 8-bits integers, reducing the model size up to 4x and speeding up inference. During inference some operations will be executed with integer kernel, others with float kernel (*hybrid operators*).\n",
    "4. __Integer quantization__: all model values (weights and activations) are quantized to 8-bit integers. This results in a 4x reduction in model size and a 3 to 4x performance improvement on CPU performance. It needs a rapresentative part of the dataset to qunatize activations. If all the operations are supported it results in a __full integer quantization__, compatible with some hardware accelartors (e.g. Coral). Otherways the incompatible operations fall back in float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T14:29:01.477840Z",
     "start_time": "2020-01-31T14:29:00.687620Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T14:29:01.503817Z",
     "start_time": "2020-01-31T14:29:01.502135Z"
    }
   },
   "outputs": [],
   "source": [
    "# set the folder path where is located the model \n",
    "DIR = './models'\n",
    "model_name = 'model.h5'\n",
    "\n",
    "model_fp = os.path.join(DIR, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T14:32:54.059099Z",
     "start_time": "2020-01-31T14:32:54.015753Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Conv2D, Flatten\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(5,3,input_shape=(150,150,3)),\n",
    "    Dense(32),\n",
    "    Activation('relu'),\n",
    "    Dense(10)\n",
    "])\n",
    "model.save(model_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Conversion without quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T14:05:04.989147Z",
     "start_time": "2020-01-31T14:05:04.931119Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(model_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Convert the model and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T14:05:09.334796Z",
     "start_time": "2020-01-31T14:05:08.178116Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103064"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the converter loading the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "tflite_model_file = os.path.join(DIR,model_name) + \".tflite\"\n",
    "pathlib.Path(tflite_model_file).write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Float16 quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T14:07:33.506262Z",
     "start_time": "2020-01-31T14:07:33.484562Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(model_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Create the converter object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T14:07:52.486886Z",
     "start_time": "2020-01-31T14:07:52.475117Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import the converter loading the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Convert the model and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T14:07:58.361529Z",
     "start_time": "2020-01-31T14:07:57.318525Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52688"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_fp16_model = converter.convert()\n",
    "\n",
    "tflite_model_fp16_file = os.path.join(DIR,model_name) + \"_fp16.tflite\"\n",
    "pathlib.Path(tflite_model_fp16_file).write_bytes(tflite_fp16_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Weight quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T14:09:13.732576Z",
     "start_time": "2020-01-31T14:09:13.707238Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(model_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Create the converter object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T14:09:14.791116Z",
     "start_time": "2020-01-31T14:09:14.778444Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import the converter loading the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Convert the model and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T14:09:17.430798Z",
     "start_time": "2020-01-31T14:09:16.384065Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27856"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_8bit_model = converter.convert()\n",
    "\n",
    "tflite_model_8bit_file = os.path.join(DIR,model_name) + \"_8bit.tflite\"\n",
    "pathlib.Path(tflite_model_8bit_file).write_bytes(tflite_8bit_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integer quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T14:29:07.176102Z",
     "start_time": "2020-01-31T14:29:07.173420Z"
    }
   },
   "outputs": [],
   "source": [
    "input_size = (150,150)  # input size of the model\n",
    "data_range = 255  # range to normalize data\n",
    "n_data = 100      # number of representative inputs\n",
    "\n",
    "DATASET_DIR = './dataset' #the directory must contain at least n_data images\n",
    "\n",
    "dataset_fp = pathlib.Path(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T14:29:07.824078Z",
     "start_time": "2020-01-31T14:29:07.780147Z"
    }
   },
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files(str(dataset_fp/\"*\"))\n",
    "\n",
    "def representative_dataset_gen():\n",
    "    for _ in range(n_data):\n",
    "        for img_f in list_ds.take(1):\n",
    "            img = tf.io.decode_image(tf.io.read_file(img_f), channels=3, dtype=tf.dtypes.uint8)\n",
    "            img = tf.image.resize(img, input_size, method=tf.image.ResizeMethod.AREA)\n",
    "            yield ([img[None]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T14:29:08.999333Z",
     "start_time": "2020-01-31T14:29:08.940541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(model_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the converter object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T14:32:59.502445Z",
     "start_time": "2020-01-31T14:32:59.471887Z"
    }
   },
   "outputs": [],
   "source": [
    "# import the converter loading the model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the model and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T14:29:16.882422Z",
     "start_time": "2020-01-31T14:29:13.280035Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Quantization not yet supported for op: REDUCE_MAX",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9632cd77440a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtflite_integer_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtflite_model_integer_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_integer.tflite\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtflite_model_integer_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtflite_integer_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/SISR/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_calibration_quantize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m       result = self._calibrate_quantize_model(result, constants.FLOAT,\n\u001b[0;32m--> 450\u001b[0;31m                                               constants.FLOAT)\n\u001b[0m\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/SISR/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py\u001b[0m in \u001b[0;36m_calibrate_quantize_model\u001b[0;34m(self, result, inference_input_type, inference_output_type)\u001b[0m\n\u001b[1;32m    237\u001b[0m     return calibrate_quantize.calibrate_and_quantize(\n\u001b[1;32m    238\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentative_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_input_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         inference_output_type, allow_float)\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_base_converter_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/SISR/lib/python3.6/site-packages/tensorflow_core/lite/python/optimize/calibrator.py\u001b[0m in \u001b[0;36mcalibrate_and_quantize\u001b[0;34m(self, dataset_gen, input_type, output_type, allow_float)\u001b[0m\n\u001b[1;32m     76\u001b[0m     return self._calibrator.QuantizeModel(\n\u001b[1;32m     77\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_numpy_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         np.dtype(output_type.as_numpy_dtype()).num, allow_float)\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/SISR/lib/python3.6/site-packages/tensorflow_core/lite/python/optimize/tensorflow_lite_wrap_calibration_wrapper.py\u001b[0m in \u001b[0;36mQuantizeModel\u001b[0;34m(self, input_py_type, output_py_type, allow_float)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mQuantizeModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_py_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_py_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensorflow_lite_wrap_calibration_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalibrationWrapper_QuantizeModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_py_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_py_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0mCalibrationWrapper_swigregister\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensorflow_lite_wrap_calibration_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalibrationWrapper_swigregister\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0mCalibrationWrapper_swigregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCalibrationWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Quantization not yet supported for op: REDUCE_MAX"
     ]
    }
   ],
   "source": [
    "tflite_integer_model = converter.convert()\n",
    "\n",
    "tflite_model_integer_file = os.path.join(DIR,model_name) + \"_integer.tflite\"\n",
    "pathlib.Path(tflite_model_integer_file).write_bytes(tflite_integer_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full integer quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:15:26.124545Z",
     "start_time": "2020-01-31T09:15:26.121274Z"
    }
   },
   "outputs": [],
   "source": [
    "input_size = (150,150)  # input size of the model\n",
    "data_range = 255  # range to normalize data\n",
    "n_data = 100      # number of representative inputs\n",
    "\n",
    "DATASET_DIR = './dataset' #the directory must contain at least n_data images\n",
    "\n",
    "dataset_fp = pathlib.Path(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-31T09:19:40.639630Z",
     "start_time": "2020-01-31T09:19:40.629344Z"
    }
   },
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files(str(dataset_fp/\"*\"))\n",
    "\n",
    "def representative_dataset_gen():\n",
    "    for _ in range(n_data):\n",
    "        for img_f in list_ds.take(1):\n",
    "            img = tf.io.decode_image(tf.io.read_file(img_f), channels=3, dtype=tf.dtypes.uint8)\n",
    "            img = tf.image.resize(img, input_size, method=tf.image.ResizeMethod.AREA)\n",
    "            yield ([img[None]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the converter object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the converter loading the model\n",
    "converter = tf.compat.v1.lite.TFLiteConverter.from_keras_model_file(model_fp) #TF2.0 currently not compatible\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset_gen\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the model and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_full_integer_model = converter.convert()\n",
    "\n",
    "tflite_model_full_integer_file = os.path.join(DIR,model_name) + \"_full_integer.tflite\")\n",
    "pathlib.Path(tflite_model_full_integer_file).write_bytes(tflite_full_integer_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SISR",
   "language": "python",
   "name": "sisr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
